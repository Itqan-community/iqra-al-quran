# app.py
"""
Quran Reciter App
Ù…Ù‡Ù…Ù‘Ø©: ØªØ·Ø¨ÙŠÙ‚ Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ„Ø§ÙˆØ© (Ø¬Ø²Ø¡ 30).
"""

import os
import time
import tempfile
import shutil
import random
import requests
import re
import unicodedata
import json
from difflib import SequenceMatcher
from flask import Flask, request, jsonify
from flask_cors import CORS
from pydub import AudioSegment
from jiwer import wer
from i18n.translations import get_translation, get_feedback_message, is_supported_language
from data.surah_names import get_english_name

# ------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ -------------
app = Flask(__name__)
app.secret_key = os.environ.get("FLASK_SECRET", "change_this_in_prod")
CORS(app)  # Enable CORS for mobile app

# Ø­Ø¯ Ø­Ø¬Ù… Ø§Ù„ØªØ­Ù…ÙŠÙ„ (10 Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª)
app.config["MAX_CONTENT_LENGTH"] = 10 * 1024 * 1024

# ------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù‘Ù† Ø¨Ù€ faster-whisper -------------
# Use the optimized CTranslate2 model for 4x speed improvement
MODEL_NAME = "OdyAsh/faster-whisper-base-ar-quran"

# Import faster-whisper for optimal performance
try:
    from faster_whisper import WhisperModel
    USE_FASTER_WHISPER = True
    print("âœ… Using faster-whisper for OPTIMAL performance (4x faster!)")
except ImportError:
    from transformers import pipeline
    USE_FASTER_WHISPER = False
    print("âš ï¸ faster-whisper not available, using transformers (slower)")

# Device configuration
import torch
gpu_available = torch.cuda.is_available()

# Global model instance
asr_model = None

def get_asr_pipeline():
    """ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ASR Ù…Ø­Ø³Ù‘Ù† Ø¨Ù€ faster-whisper Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø£Ø¯Ø§Ø¡"""
    global asr_model, MODEL_NAME, USE_FASTER_WHISPER
    
    if asr_model is None:
        print(f"ğŸš€ Loading OPTIMIZED ASR model: {MODEL_NAME}")
        device_info = 'GPU' if gpu_available else 'CPU'
        print(f"ğŸ¯ Device: {device_info}")
        
        start_time = time.time()
        
        try:
            if USE_FASTER_WHISPER:
                # Use faster-whisper (CTranslate2) - Much faster!
                device = "cuda" if gpu_available else "cpu"
                compute_type = "float16" if gpu_available else "int8"  # Quantization for speed
                
                print(f"ğŸ”¥ Loading with faster-whisper (device={device}, compute_type={compute_type})")
                asr_model = WhisperModel(
                    MODEL_NAME,
                    device=device,
                    compute_type=compute_type,
                    download_root=None,
                    local_files_only=False
                )
                
                load_time = time.time() - start_time
                print(f"âœ… faster-whisper model loaded in {load_time:.2f} seconds")
                
                # Model warmup with faster-whisper
                print("ğŸ”¥ Warming up faster-whisper model...")
                warmup_start = time.time()
                try:
                    import numpy as np
                    # Create 1 second of silence for warmup
                    dummy_audio = np.zeros(16000, dtype=np.float32)
                    
                    # Run warmup inference
                    segments, info = asr_model.transcribe(dummy_audio, language="ar")
                    list(segments)  # Consume the generator
                    
                    warmup_time = time.time() - warmup_start
                    print(f"ğŸš€ faster-whisper warmed up in {warmup_time:.2f} seconds!")
                    print("ğŸ’¡ Model ready for BLAZING FAST inference!")
                    
                except Exception as e:
                    print(f"âš ï¸ faster-whisper warmup failed: {e}")
                
            else:
                # Fallback to transformers pipeline
                device = 0 if gpu_available else -1
                asr_model = pipeline(
                    "automatic-speech-recognition",
                    model="tarteel-ai/whisper-base-ar-quran",
                    device=device,
                    torch_dtype=torch.float16 if gpu_available else torch.float32
                )
                
                load_time = time.time() - start_time
                print(f"âœ… Transformers pipeline loaded in {load_time:.2f} seconds")
                
        except Exception as e:
            print(f"âŒ Error loading optimized model: {e}")
            print("ğŸ”„ Falling back to basic model...")
            
            # Ultimate fallback
            if USE_FASTER_WHISPER:
                try:
                    asr_model = WhisperModel("base", device="cpu", compute_type="int8")
                    print("âœ… Fallback faster-whisper model loaded")
                except:
                    USE_FASTER_WHISPER = False
            
            if not USE_FASTER_WHISPER:
                device = 0 if gpu_available else -1
                from transformers import pipeline
                asr_model = pipeline("automatic-speech-recognition", model="openai/whisper-base", device=device)
                print("âœ… Ultimate fallback to transformers model loaded")
    
    return asr_model

def transcribe_audio_optimized(audio_path):
    """Transcribe audio using the optimized faster-whisper model"""
    model = get_asr_pipeline()
    
    if USE_FASTER_WHISPER:
        # Use faster-whisper transcription (MUCH FASTER!)
        segments, info = model.transcribe(audio_path, language="ar")
        
        # Extract text from segments
        transcription = ""
        for segment in segments:
            transcription += segment.text + " "
        
        return {
            "text": transcription.strip(),
            "language": info.language,
            "language_probability": info.language_probability,
            "duration": info.duration,
            "optimized": True
        }
    else:
        # Use transformers pipeline (fallback)
        import numpy as np
        import soundfile as sf
        
        if isinstance(audio_path, str):
            # Load audio file as numpy array
            audio, sample_rate = sf.read(audio_path)
            if sample_rate != 16000:
                import librosa
                audio = librosa.resample(audio, orig_sr=sample_rate, target_sr=16000)
        else:
            audio = audio_path
            
        result = model(audio)
        return {"text": result["text"], "optimized": False}

# ------------- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª API Ù„Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ… -------------
API_BASE_URL = "https://api.quran.com/api/v4"


# Ù…ØªØºÙŠØ±Ø§Øª ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª Ù„Ù„Ø³ÙˆØ± (Cache)
_cached_surahs = None
_cache_timestamp = None
CACHE_DURATION = 3600  # Ø³Ø§Ø¹Ø© ÙˆØ§Ø­Ø¯Ø©


# ------------- ÙˆØ¸Ø§Ø¦Ù API Ù„Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ… -------------
def clean_html_tags(text):
    """Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª HTML Ù…Ù† Ø§Ù„Ù†Øµ."""
    clean_text = re.sub(r"<sup.*?</sup>", "", text)
    clean_text = re.sub(r"<[^>]+>", "", clean_text)
    return clean_text.strip()


def get_all_surahs():
    """Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø³ÙˆØ± Ù…Ù† API Ù…Ø¹ Ù†Ø¸Ø§Ù… ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª."""
    global _cached_surahs, _cache_timestamp

    # ÙØ­Øµ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
    if _cached_surahs and _cache_timestamp:
        if (time.time() - _cache_timestamp) < CACHE_DURATION:
            return _cached_surahs, None

    url = f"{API_BASE_URL}/chapters"
    try:
        response = requests.get(url, timeout=15)
        response.raise_for_status()
        chapters = response.json().get("chapters", [])

        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Ù…Ù†Ø§Ø³Ø¨ Ù…Ø¹ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
        surahs = [(ch["id"], ch["name_arabic"], ch.get("name_simple", f"Surah {ch['id']}")) for ch in chapters]

        # Ø­ÙØ¸ ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
        _cached_surahs = surahs
        _cache_timestamp = time.time()

        return surahs, None

    except requests.exceptions.RequestException as e:
        print(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø³ÙˆØ±: {e}")
        # ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£ØŒ Ø§Ø±Ø¬Ø¹ Ù„Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙŠØ¯ÙˆÙŠØ© Ù„Ø¬Ø²Ø¡ Ø¹Ù…Ù‘ Ù…Ø¹ Ø£Ø³Ù…Ø§Ø¡ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
        juz30_surahs = get_juz30_surahs_fallback()
        # Add English names to the fallback data
        enhanced_surahs = []
        for surah_id, arabic_name in juz30_surahs:
            english_name = get_english_name(surah_id)
            enhanced_surahs.append((surah_id, arabic_name, english_name))
        return (
            enhanced_surahs,
            f"ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø¨Ø³Ø¨Ø¨ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø´Ø¨ÙƒØ©: {e}",
        )


def get_juz30_surahs():
    """Ø¬Ù„Ø¨ Ø³ÙˆØ± Ø¬Ø²Ø¡ Ø¹Ù…Ù‘ ÙÙ‚Ø· Ù…Ù† API."""
    all_surahs, error = get_all_surahs()
    if error:
        return all_surahs, error

    # ØªØµÙÙŠØ© Ø§Ù„Ø³ÙˆØ± Ù„Ø¬Ø²Ø¡ Ø¹Ù…Ù‘ (Ø§Ù„Ø³ÙˆØ± Ù…Ù† 78 Ø¥Ù„Ù‰ 114)
    juz30_surahs = [(id, arabic_name, english_name) for id, arabic_name, english_name in all_surahs if 78 <= id <= 114]
    return juz30_surahs, None


def get_juz30_surahs_fallback():
    """Ù‚Ø§Ø¦Ù…Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù„Ø³ÙˆØ± Ø¬Ø²Ø¡ Ø¹Ù…Ù‘ ÙÙŠ Ø­Ø§Ù„Ø© Ø¹Ø¯Ù… ØªÙˆÙØ± Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª."""
    return [
        (78, "Ø§Ù„Ù†Ø¨Ø£", "An-Naba"),
        (79, "Ø§Ù„Ù†Ø§Ø²Ø¹Ø§Øª", "An-Naziat"),
        (80, "Ø¹Ø¨Ø³", "Abasa"),
        (81, "Ø§Ù„ØªÙƒÙˆÙŠØ±", "At-Takwir"),
        (82, "Ø§Ù„Ø§Ù†ÙØ·Ø§Ø±", "Al-Infitar"),
        (83, "Ø§Ù„Ù…Ø·ÙÙÙŠÙ†", "Al-Mutaffifin"),
        (84, "Ø§Ù„Ø§Ù†Ø´Ù‚Ø§Ù‚", "Al-Inshiqaq"),
        (85, "Ø§Ù„Ø¨Ø±ÙˆØ¬", "Al-Buruj"),
        (86, "Ø§Ù„Ø·Ø§Ø±Ù‚", "At-Tariq"),
        (87, "Ø§Ù„Ø£Ø¹Ù„Ù‰", "Al-A'la"),
        (88, "Ø§Ù„ØºØ§Ø´ÙŠØ©", "Al-Ghashiyah"),
        (89, "Ø§Ù„ÙØ¬Ø±", "Al-Fajr"),
        (90, "Ø§Ù„Ø¨Ù„Ø¯", "Al-Balad"),
        (91, "Ø§Ù„Ø´Ù…Ø³", "Ash-Shams"),
        (92, "Ø§Ù„Ù„ÙŠÙ„", "Al-Layl"),
        (93, "Ø§Ù„Ø¶Ø­Ù‰", "Ad-Duha"),
        (94, "Ø§Ù„Ø´Ø±Ø­", "Ash-Sharh"),
        (95, "Ø§Ù„ØªÙŠÙ†", "At-Tin"),
        (96, "Ø§Ù„Ø¹Ù„Ù‚", "Al-Alaq"),
        (97, "Ø§Ù„Ù‚Ø¯Ø±", "Al-Qadr"),
        (98, "Ø§Ù„Ø¨ÙŠÙ†Ø©", "Al-Bayyinah"),
        (99, "Ø§Ù„Ø²Ù„Ø²Ù„Ø©", "Az-Zalzalah"),
        (100, "Ø§Ù„Ø¹Ø§Ø¯ÙŠØ§Øª", "Al-Adiyat"),
        (101, "Ø§Ù„Ù‚Ø§Ø±Ø¹Ø©", "Al-Qariah"),
        (102, "Ø§Ù„ØªÙƒØ§Ø«Ø±", "At-Takathur"),
        (103, "Ø§Ù„Ø¹ØµØ±", "Al-Asr"),
        (104, "Ø§Ù„Ù‡Ù…Ø²Ø©", "Al-Humazah"),
        (105, "Ø§Ù„ÙÙŠÙ„", "Al-Fil"),
        (106, "Ù‚Ø±ÙŠØ´", "Quraysh"),
        (107, "Ø§Ù„Ù…Ø§Ø¹ÙˆÙ†", "Al-Ma'un"),
        (108, "Ø§Ù„ÙƒÙˆØ«Ø±", "Al-Kawthar"),
        (109, "Ø§Ù„ÙƒØ§ÙØ±ÙˆÙ†", "Al-Kafirun"),
        (110, "Ø§Ù„Ù†ØµØ±", "An-Nasr"),
        (111, "Ø§Ù„Ù…Ø³Ø¯", "Al-Masad"),
        (112, "Ø§Ù„Ø¥Ø®Ù„Ø§Øµ", "Al-Ikhlas"),
        (113, "Ø§Ù„ÙÙ„Ù‚", "Al-Falaq"),
        (114, "Ø§Ù„Ù†Ø§Ø³", "An-Nas"),
    ]


def get_surah_verses(surah_id):
    """Ø¬Ù„Ø¨ Ø¢ÙŠØ§Øª Ø³ÙˆØ±Ø© Ù…Ø¹ÙŠÙ†Ø©."""
    url = f"{API_BASE_URL}/chapters/{surah_id}/verses"
    try:
        response = requests.get(url, timeout=15)
        response.raise_for_status()
        data = response.json()
        verses = data.get("verses", [])
        return verses, None
    except requests.exceptions.RequestException as e:
        print(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø¢ÙŠØ§Øª Ø§Ù„Ø³ÙˆØ±Ø© {surah_id}: {e}")
        return [], f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø¢ÙŠØ§Øª Ø§Ù„Ø³ÙˆØ±Ø©: {e}"


def get_ayah_from_quran_api(surah_id, ayah_number):
    """Ø¬Ù„Ø¨ Ù†Øµ Ø¢ÙŠØ© Ù…Ø¹ÙŠÙ†Ø© Ù…Ù† API Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ (Quran.com)."""
    url = f"{API_BASE_URL}/verses/by_key/{surah_id}:{ayah_number}"
    params = {"fields": "text_imlaei"}
    try:
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        verse = data.get("verse", {})
        text = verse.get("text_imlaei", "")
        return clean_html_tags(text)
    except Exception as e:
        print(f"Ø®Ø·Ø£ ÙÙŠ API Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ: {e}")
    return ""


def get_ayah_text(surah_id, ayah_number):
    """Ø¬Ù„Ø¨ Ù†Øµ Ø§Ù„Ø¢ÙŠØ© Ù…Ø¹ Ù†Ø¸Ø§Ù… Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù…ØªØ¹Ø¯Ø¯."""
    # Ø£ÙˆÙ„Ø§Ù‹: Ø¬Ø±Ø¨ API Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    text = get_ayah_from_quran_api(surah_id, ayah_number)
    if text:
        return text
    # ÙˆØ¥Ù„Ø§ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ Ù…ØªØ§Ø­
    return ""


# ------------- ÙˆØ¸Ø§Ø¦Ù Ù…Ø³Ø§Ø¹Ø¯Ø© -------------
def remove_diacritics(text):
    """Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„ - Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ Ø­Ø§Ù„Ø§Øª Ø®Ø§ØµØ© ÙÙ‚Ø·"""
    return "".join(
        c for c in unicodedata.normalize("NFD", text) if unicodedata.category(c) != "Mn"
    )


def normalize_text_for_compare(text):
    """ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†Øµ Ù…Ø¹ Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„ØªØ´ÙƒÙŠÙ„ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©"""
    if not text:
        return ""

    # Ù„Ø§ Ù†Ø²ÙŠÙ„ Ø§Ù„ØªØ´ÙƒÙŠÙ„ØŒ ÙÙ‚Ø· Ù†Ø²ÙŠÙ„ Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù…
    text = re.sub(
        r"[^\w\s\u0600-\u06FF\u064B-\u065F\u0610-\u061A\u06D6-\u06ED]", "", text
    )  # Ø§Ø­ØªÙØ¸ Ø¨Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„ØªØ´ÙƒÙŠÙ„
    text = unicodedata.normalize("NFKC", text)  # ØªØ·Ø¨ÙŠØ¹ Unicode Ù„Ù„ØªØ´ÙƒÙŠÙ„
    return " ".join(text.split())  # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª


def color_diff_html(ref_text, hyp_text):
    """
    ØªÙ„ÙˆÙŠÙ† ÙƒÙ„Ù…Ø©-Ø¨ÙƒÙ„Ù…Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… opcodes Ù…Ù† SequenceMatcher.
    Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ØªØ·Ø§Ø¨Ù‚Ø© ØªØµØ¨Ø­ Ø¨Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ø£Ø®Ø¶Ø±ØŒ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø³ØªØ¨Ø¯Ù„Ø© Ø¨Ø§Ù„Ø£Ø­Ù…Ø±ØŒ
    Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ø¨Ø§Ù„Ø¨Ø±ØªÙ‚Ø§Ù„ÙŠØŒ Ø§Ù„Ø­Ø°ÙˆÙØ§Øª Ø¨Ø®Ø· Ù…Ø§Ø¦Ù„.
    """
    ref_words = ref_text.split()
    hyp_words = hyp_text.split()
    s = SequenceMatcher(None, ref_words, hyp_words)
    parts = []
    for tag, i1, i2, j1, j2 in s.get_opcodes():
        if tag == "equal":
            for w in ref_words[i1:i2]:
                parts.append(f"<span class='word correct'>{w}</span>")
        elif tag == "replace":
            for w in hyp_words[j1:j2]:
                parts.append(f"<span class='word wrong'>{w}</span>")
        elif tag == "insert":
            for w in hyp_words[j1:j2]:
                parts.append(f"<span class='word insert'>{w}</span>")
        elif tag == "delete":
            for w in ref_words[i1:i2]:
                parts.append(f"<span class='word deleted'>{w}</span>")
    return " ".join(parts)


def create_word_analysis(ref_text, hyp_text):
    """
    Create structured word-by-word analysis data for API consumption.
    Returns list of word objects with text and status.
    """
    if not ref_text or not hyp_text:
        return []
    
    ref_words = ref_text.split()
    hyp_words = hyp_text.split()
    s = SequenceMatcher(None, ref_words, hyp_words)
    analysis = []
    
    for tag, i1, i2, j1, j2 in s.get_opcodes():
        if tag == "equal":
            # Correct words
            for w in ref_words[i1:i2]:
                analysis.append({
                    "text": w,
                    "status": "correct",
                    "type": "reference"
                })
        elif tag == "replace":
            # Wrong words - show both reference and detected
            for idx, w in enumerate(ref_words[i1:i2]):
                analysis.append({
                    "text": w,
                    "status": "wrong",
                    "type": "reference"
                })
            for idx, w in enumerate(hyp_words[j1:j2]):
                analysis.append({
                    "text": w,
                    "status": "wrong",
                    "type": "detected"
                })
        elif tag == "insert":
            # Extra words (inserted by user)
            for w in hyp_words[j1:j2]:
                analysis.append({
                    "text": w,
                    "status": "insert",
                    "type": "detected"
                })
        elif tag == "delete":
            # Missing words (should have been said)
            for w in ref_words[i1:i2]:
                analysis.append({
                    "text": w,
                    "status": "missing",
                    "type": "reference"
                })
    
    return analysis


def convert_to_wav(src_path):
    """
    ØªØ­ÙˆÙŠÙ„ Ø£ÙŠ Ù…Ù„Ù ØµÙˆØªÙŠ ÙˆØ§Ø±Ø¯ (webm/ogg/mp3) Ø¥Ù„Ù‰ WAV Ù…ÙˆÙ†Ùˆ 16kHz - Ù…Ø­Ø³Ù‘Ù† Ù„Ù„Ø³Ø±Ø¹Ø©.
    Ø¥Ø±Ø¬Ø§Ø¹ Ù…Ø³Ø§Ø± Ù…Ù„Ù WAV Ø§Ù„Ø¬Ø¯ÙŠØ¯.
    """
    print(f"ğŸµ Converting audio: {os.path.basename(src_path)}")
    convert_start = time.time()
    
    basename = os.path.splitext(os.path.basename(src_path))[0]
    out_wav = os.path.join(tempfile.gettempdir(), f"{basename}_fast.wav")
    
    audio = AudioSegment.from_file(src_path)
    
    # Aggressive performance optimizations
    audio = audio.set_channels(1)  # Mono for faster processing
    audio = audio.set_frame_rate(16000)  # Whisper's optimal rate
    audio = audio.set_sample_width(2)  # 16-bit for balance of quality/speed
    
    # Trim silence to reduce processing time
    audio = audio.strip_silence(silence_len=100, silence_thresh=-50)
    
    # Limit audio length to 30 seconds (Whisper's max anyway)
    if len(audio) > 30000:  # 30 seconds
        print("â° Audio > 30s, trimming for faster processing")
        audio = audio[:30000]
    
    # Fast export with minimal processing
    audio.export(out_wav, format="wav", parameters=["-ac", "1", "-ar", "16000"])
    
    convert_time = time.time() - convert_start
    print(f"âœ… Audio converted in {convert_time:.2f}s")
    
    return out_wav


# ------------- Ù…Ù†Ø·Ù‚ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªÙ„Ø§ÙˆØ© (Ù…Ø­Ø¯Ù‘Ø«) -------------
def evaluate_recitation(file_path, surah_id, ayah_number):
    """
    1) ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ WAV Ø¥Ù† Ù„Ø²Ù…
    2) ØªØ´ØºÙŠÙ„ ASR Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ
    3) Ø¬Ù„Ø¨ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ Ù…Ù† API
    4) Ù…Ù‚Ø§Ø±Ù†Ø©ØŒ Ø­Ø³Ø§Ø¨ WERØŒ ØªØ¬Ù‡ÙŠØ² HTML Ù…Ù„ÙˆÙ† ÙˆØ¥Ø®Ø±Ø§Ø¬ Ø±Ø³Ø§Ù„Ø© ØªØ´Ø¬ÙŠØ¹
    """
    # ØªØ£ÙƒØ¯ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª (Ø£Ø³Ø§Ø³ÙŠØ©)
    try:
        wav_path = convert_to_wav(file_path)
    except Exception as e:
        print("Audio convert error:", e)
        # Ø¥Ø°Ø§ Ø§Ù„ØªØ­ÙˆÙŠÙ„ ÙØ´Ù„ØŒ Ø¬Ø±Ù‘Ø¨ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø£Ù†Ø¨ÙˆØ¨
        wav_path = file_path

    # 1) Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…
    asr_pipeline = get_asr_pipeline()
    asr_result = asr_pipeline(wav_path)
    hypothesis = asr_result.get("text", "").strip()

    # 2) Ù†Øµ Ø§Ù„Ù…Ø±Ø¬Ø¹ Ù…Ù† API
    reference_raw = get_ayah_text(surah_id, ayah_number)
    if not reference_raw:
        reference_raw = ""

    # 3) ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†ØµÙˆØµ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© ÙˆØ­Ø³Ø§Ø¨ WER
    ref_norm = normalize_text_for_compare(reference_raw)
    hyp_norm = normalize_text_for_compare(hypothesis)

    # Ø­Ø³Ø§Ø¨ WER Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… jiwer
    try:
        error = wer(ref_norm, hyp_norm)
    except Exception:
        error = 1.0

    # 4) ØªÙˆÙ„ÙŠØ¯ HTML Ù…Ù„ÙˆÙ†
    colored = color_diff_html(ref_norm, hyp_norm)

    # 5)
    if error <= 0.10:
        feedback = "Ù…Ù…ØªØ§Ø²"
    elif error <= 0.30:
        feedback = "Ø§Ù†ØªØ¨Ù‡ Ù„Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡"
    else:
        feedback = "Ø¬Ø±Ø¨ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰!"

    return {
        "hypothesis": hypothesis,
        "reference_raw": reference_raw,
        "ref_norm": ref_norm,
        "hyp_norm": hyp_norm,
        "wer": error,
        "colored_html": colored,
        "feedback": feedback,
        "wav_path": wav_path,
    }


# ------------- Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„ÙˆÙŠØ¨ (Routes) -------------
# Flask template route removed - frontend is now served by Express/React


@app.route("/api/get_ayah", methods=["GET"])
def get_ayah_api():
    """API Ø¨Ø³ÙŠØ· Ù„Ø¬Ù„Ø¨ Ù†Øµ Ø§Ù„Ø¢ÙŠØ© (ÙŠØ³ØªØ®Ø¯Ù…Ù‡ Ø§Ù„Ø¬Ø§ÙØ§Ø³ÙƒØ±Ø¨Øª ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©)."""
    surah = request.args.get("surah")
    ayah = request.args.get("ayah")
    if not surah or not ayah:
        return jsonify({"text": ""}), 400

    text = get_ayah_text(surah, ayah)
    return jsonify({"text": text or ""})


@app.route("/api/get_surah_info/<int:surah_id>", methods=["GET"])
def get_surah_info(surah_id):
    """Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø³ÙˆØ±Ø© ÙˆØ¹Ø¯Ø¯ Ø¢ÙŠØ§ØªÙ‡Ø§."""
    url = f"{API_BASE_URL}/chapters/{surah_id}"
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        data = response.json()
        chapter = data.get("chapter", {})
        return jsonify(
            {
                "id": chapter.get("id"),
                "name_arabic": chapter.get("name_arabic"),
                "verses_count": chapter.get("verses_count"),
                "revelation_place": chapter.get("revelation_place"),
            }
        )
    except Exception as e:
        print(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø³ÙˆØ±Ø©: {e}")
        return jsonify({"error": "ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø³ÙˆØ±Ø©"}), 500


@app.route("/api/surahs", methods=["GET"])
def api_juz30_surahs():
    """API Ù„Ø¬Ù„Ø¨ Ø³ÙˆØ± Ø¬Ø²Ø¡ Ø¹Ù…Ù‘ ÙÙ‚Ø·."""
    surahs_raw, error = get_juz30_surahs()
    
    # Convert to mobile-compatible format
    surahs = []
    for surah_data in surahs_raw:
        if isinstance(surah_data, (list, tuple)) and len(surah_data) >= 2:
            surah_id = surah_data[0]
            arabic_name = surah_data[1]
            # Use provided English name if available (3-tuple), otherwise fallback to get_english_name
            english_name = surah_data[2] if len(surah_data) > 2 else get_english_name(surah_id)
            
            surahs.append({
                'id': surah_id,
                'name_arabic': arabic_name,
                'name_simple': english_name,
                'name_english': english_name
            })
    
    if error:
        return jsonify({"surahs": surahs, "error": error}), 200
    return jsonify({"surahs": surahs})


@app.route("/api/all_surahs", methods=["GET"])
def api_all_surahs():
    """API Ù„Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø³ÙˆØ±."""
    surahs_raw, error = get_all_surahs()
    
    # Convert to mobile-compatible format
    surahs = []
    for surah_data in surahs_raw:
        if isinstance(surah_data, (list, tuple)) and len(surah_data) >= 2:
            english_name = surah_data[2] if len(surah_data) > 2 else f"Surah {surah_data[0]}"
            surahs.append({
                'id': surah_data[0],
                'name_arabic': surah_data[1],
                'name_simple': english_name,
                'name_english': english_name
            })
    
    if error:
        return jsonify({"surahs": surahs, "error": error}), 200
    return jsonify({"surahs": surahs})


@app.route("/health")
@app.route("/api/health")
def health_check():
    """Health check endpoint for monitoring."""
    language = request.args.get('lang', 'en')
    if not is_supported_language(language):
        language = 'en'
    
    return jsonify({
        "status": "healthy",
        "service": get_translation("service_name", language),
        "message": get_translation("service_healthy", language),
        "supported_languages": ["en", "ar"]
    })


@app.route("/api/check", methods=["POST"])
def api_check_recitation():
    """API endpoint for mobile app recitation checking with language support."""
    try:
        # Get language preference
        language = request.form.get('language', 'en')
        if not is_supported_language(language):
            language = 'en'
        
        # Validate input
        audio_file = request.files.get('audio')
        if not audio_file or audio_file.filename == "":
            return jsonify({
                "error": get_translation("missing_audio", language)
            }), 400

        try:
            surah_id = int(request.form.get('surah_id'))
            ayah_number = int(request.form.get('ayah_number'))
        except (TypeError, ValueError):
            return jsonify({
                "error": get_translation("missing_surah", language)
            }), 400

        # Process the audio file temporarily
        tmp_dir = tempfile.mkdtemp(prefix="iqra_api_")
        try:
            saved_path = os.path.join(tmp_dir, audio_file.filename)
            audio_file.save(saved_path)

            # Evaluate recitation
            result = evaluate_recitation_api(saved_path, surah_id, ayah_number, language)
            return jsonify(result)

        finally:
            # Clean up temporary files
            try:
                shutil.rmtree(tmp_dir)
            except Exception:
                pass

    except Exception as e:
        import traceback
        print(f"âŒ API check error: {e}")
        print(f"ğŸ” Traceback: {traceback.format_exc()}")
        return jsonify({
            "error": get_translation("processing_error", language),
            "debug_message": str(e)
        }), 500


def evaluate_recitation_web(file_path, surah_id, ayah_number, language="ar"):
    """
    Evaluate recitation for web interface with language support.
    Returns dictionary for template rendering.
    """
    try:
        # Convert audio to WAV if needed
        try:
            wav_path = convert_to_wav(file_path)
        except Exception as e:
            print("Audio convert error:", e)
            wav_path = file_path

        # ASR processing
        asr_pipeline = get_asr_pipeline()
        asr_result = asr_pipeline(wav_path)
        hypothesis = asr_result.get("text", "").strip()

        # Get reference text
        reference_raw = get_ayah_text(surah_id, ayah_number)
        if not reference_raw:
            return {
                "error": get_translation("ayah_not_found", language)
            }

        # Normalize texts for comparison
        ref_norm = normalize_text_for_compare(reference_raw)
        hyp_norm = normalize_text_for_compare(hypothesis)

        # Calculate WER
        try:
            wer_score = wer(ref_norm, hyp_norm) if ref_norm and hyp_norm else 1.0
        except Exception:
            wer_score = 1.0

        # Get contextual feedback
        feedback = get_feedback_message(wer_score, language)

        # Create colored diff for web display
        colored_html = create_colored_diff(ref_norm, hyp_norm)

        return {
            "success": True,
            "wer_score": wer_score,
            "accuracy_percentage": round((1 - wer_score) * 100, 1),
            "detected_text": hypothesis,
            "reference_text": reference_raw,
            "feedback": feedback,
            "colored_diff": colored_html,
            "language": language,
            "surah_id": surah_id,
            "ayah_number": ayah_number
        }

    except Exception as e:
        print(f"Web evaluation error: {e}")
        return {
            "error": get_translation("processing_error", language)
        }


def evaluate_recitation_api(file_path, surah_id, ayah_number, language="en"):
    """
    Evaluate recitation for API with PERFORMANCE MONITORING.
    Returns JSON-formatted result.
    """
    total_start = time.time()
    
    try:
        print(f"ğŸ¯ Starting PERFORMANCE-MONITORED evaluation for Surah {surah_id}, Ayah {ayah_number}")
        
        # 1. Convert audio to WAV if needed (TIMED)
        audio_start = time.time()
        try:
            wav_path = convert_to_wav(file_path)
        except Exception as e:
            print(f"âŒ Audio convert error: {e}")
            wav_path = file_path
        audio_time = time.time() - audio_start

        # 2. ASR processing with OPTIMIZED faster-whisper (TIMED)
        print("ğŸ¤ Starting OPTIMIZED speech recognition...")
        asr_start = time.time()
        
        # Use the optimized transcription function
        asr_result = transcribe_audio_optimized(wav_path)
        hypothesis = asr_result.get("text", "").strip()
        is_optimized = asr_result.get("optimized", False)
        
        asr_time = time.time() - asr_start
        print(f"ğŸš€ {'FASTER-WHISPER' if is_optimized else 'TRANSFORMERS'} transcription: '{hypothesis[:50]}...'")
        print(f"âš¡ Speech recognition time: {asr_time:.2f}s")

        # 3. Get reference text (TIMED)
        ref_start = time.time()
        reference_raw = get_ayah_text(surah_id, ayah_number)
        if not reference_raw:
            return {
                "error": get_translation("ayah_not_found", language),
                "processing_time": round(time.time() - total_start, 2)
            }
        ref_time = time.time() - ref_start

        # 4. Text processing (TIMED)
        text_start = time.time()
        ref_norm = normalize_text_for_compare(reference_raw)
        hyp_norm = normalize_text_for_compare(hypothesis)

        # Calculate WER
        try:
            wer_score = wer(ref_norm, hyp_norm) if ref_norm and hyp_norm else 1.0
        except Exception:
            wer_score = 1.0

        # Get contextual feedback
        feedback = get_feedback_message(wer_score, language)

        # Create word-by-word analysis
        word_analysis = create_word_analysis(ref_norm, hyp_norm)
        text_time = time.time() - text_start
        
        total_time = time.time() - total_start
        
        # Performance logging
        print(f"ğŸ“Š PERFORMANCE BREAKDOWN:")
        print(f"   ğŸµ Audio conversion: {audio_time:.2f}s")
        print(f"   ğŸ¤ Speech recognition: {asr_time:.2f}s")
        print(f"   ğŸ“– Reference lookup: {ref_time:.2f}s")
        print(f"   ğŸ“ Text processing: {text_time:.2f}s")
        print(f"   â±ï¸ TOTAL TIME: {total_time:.2f}s")

        return {
            "success": True,
            "wer_score": wer_score,
            "accuracy_percentage": round((1 - wer_score) * 100, 1),
            "detected_text": hypothesis,
            "reference_text": reference_raw,
            "feedback": feedback,
            "word_analysis": word_analysis,
            "language": language,
            "surah_id": surah_id,
            "ayah_number": ayah_number,
            # PERFORMANCE METRICS
            "processing_time": round(total_time, 2),
            "performance_breakdown": {
                "audio_conversion": round(audio_time, 2),
                "speech_recognition": round(asr_time, 2),
                "reference_lookup": round(ref_time, 2),
                "text_processing": round(text_time, 2)
            },
            "model_used": MODEL_NAME + (" (faster-whisper)" if USE_FASTER_WHISPER else " (transformers)")
        }

    except Exception as e:
        import traceback
        total_time = time.time() - total_start
        print(f"âŒ Evaluation error: {e}")
        print(f"ğŸ” Traceback: {traceback.format_exc()}")
        return {
            "error": get_translation("processing_error", language),
            "debug_message": str(e),
            "processing_time": round(total_time, 2)
        }


# ------------- ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ -------------
if __name__ == "__main__":
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„API Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„
    print("Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ API Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…...")
    surahs, error = get_juz30_surahs()
    if error:
        print(f"ØªØ­Ø°ÙŠØ±: {error}")
        print(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(surahs)} Ø³ÙˆØ±Ø© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ©")
    else:
        print(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(surahs)} Ø³ÙˆØ±Ø© Ù…Ù† API Ø¨Ù†Ø¬Ø§Ø­")

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5001))
    app.run(host="0.0.0.0", port=port, debug=True)
